# Ecossistema Hadoop

## 1. O que é o Apache Hadoop?

O Apache Hadoop é um framework open-source que permite o processamento distribuído de grandes conjuntos de dados em clusters de computadores. Ele foi projetado para escalar de um único servidor para milhares de máquinas, oferecendo um alto grau de tolerância a falhas.

### Principais Componentes:

1.  **HDFS (Hadoop Distributed File System):** Um sistema de arquivos distribuído que fornece acesso de alto desempenho aos dados de aplicação. É a camada de armazenamento do Hadoop.
2.  **YARN (Yet Another Resource Negotiator):** O gerenciador de recursos do cluster, responsável por alocar CPU e memória para as aplicações.
3.  **MapReduce:** Um modelo de programação para processamento de dados em paralelo. Embora ainda seja usado, o Apache Spark (que veremos no próximo módulo) tornou-se a alternativa mais moderna e eficiente.

[Informações sobre o ecossistema hadoop](https://hadoopecosystemtable.github.io/)

### Laboratórios

Aula 2 - Prática com Hadoop no Colab - [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1lsYb7xP6gFk-Zwyzwl0Hkbk3aWIQ5KpK?usp=sharing)

Aula 3 - Prática com Spark no colab - [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1QlQiUuRNcbWFW3xLuY1BoUWlrPyZGxL8?usp=sharing)

### Apostila



### Apresentação


### Dataset
[Brasilian e-commerce](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)

